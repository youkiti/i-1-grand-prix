"""
Gemini Deep Research Agent å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Gemini Deep Research ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒªã‚µãƒ¼ãƒã‚¿ã‚¹ã‚¯ã‚’
è‡ªå¾‹çš„ã«è¨ˆç”»ãƒ»å®Ÿè¡Œã—ã€å¼•ç”¨æ–‡çŒ®ä»˜ãã®è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: https://ai.google.dev/gemini-api/docs/deep-research

ä½¿ç”¨ä¾‹:
    # åŸºæœ¬çš„ãªãƒªã‚µãƒ¼ãƒ
    python scripts/deep_research.py "Research the history of Google TPUs."
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š
    python scripts/deep_research.py "EVãƒãƒƒãƒ†ãƒªãƒ¼ã®ç«¶äº‰ç’°å¢ƒã‚’èª¿æŸ»" --output report.md
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆé€²æ—è¡¨ç¤ºï¼‰
    python scripts/deep_research.py "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®æœ€æ–°å‹•å‘" --stream
    
    # å‡ºåŠ›å½¢å¼ã‚’æŒ‡å®š
    python scripts/deep_research.py "AIè¦åˆ¶ã®å›½éš›æ¯”è¼ƒ" --format "æŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã§ã€1.æ¦‚è¦ 2.ä¸»è¦å›½ã®æ”¿ç­– 3.æ¯”è¼ƒè¡¨ ã‚’å«ã‚€"

å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
    pip install google-genai
"""

import argparse
import os
import sys
import time
from datetime import datetime
from pathlib import Path

try:
    from google import genai
except ImportError:
    print("ã‚¨ãƒ©ãƒ¼: google-genai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install google-genai")
    sys.exit(1)

from dotenv import load_dotenv

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# è¨­å®š
AGENT_NAME = "deep-research-pro-preview-12-2025"
POLL_INTERVAL_SECONDS = 10
MAX_WAIT_MINUTES = 60


def create_client() -> genai.Client:
    """Gemini API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹ã€‚"""
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("  .env ãƒ•ã‚¡ã‚¤ãƒ«ã« GOOGLE_API_KEY=your_key ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    
    return genai.Client(api_key=api_key)


def run_research_polling(client: genai.Client, prompt: str) -> tuple[str, dict]:
    """
    ãƒãƒ¼ãƒªãƒ³ã‚°æ–¹å¼ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    é•·æ™‚é–“ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã—ã€å®Œäº†ã¾ã§å¾…æ©Ÿã™ã‚‹ã€‚
    
    Returns:
        tuple: (çµæœãƒ†ã‚­ã‚¹ãƒˆ, ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸)
    """
    print(f"ãƒªã‚µãƒ¼ãƒé–‹å§‹...", flush=True)
    print(f"  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:100]}{'...' if len(prompt) > 100 else ''}", flush=True)
    print(f"  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {AGENT_NAME}", flush=True)
    print(flush=True)
    
    try:
        interaction = client.interactions.create(
            input=prompt,
            agent=AGENT_NAME,
            background=True
        )
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", flush=True)
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    interaction_id = interaction.id
    print(f"ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ ID: {interaction_id}")
    print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒãƒ¼ãƒªãƒ³ã‚°ä¸­ (æœ€å¤§ {MAX_WAIT_MINUTES} åˆ†)...")
    print()
    
    start_time = time.time()
    max_seconds = MAX_WAIT_MINUTES * 60
    
    while True:
        interaction = client.interactions.get(interaction_id)
        elapsed = time.time() - start_time
        
        if interaction.status == "completed":
            print(f"\nâœ“ ãƒªã‚µãƒ¼ãƒå®Œäº† ({elapsed:.1f} ç§’)")
            metadata = {
                "interaction_id": interaction_id,
                "agent": AGENT_NAME,
                "status": interaction.status,
                "execution_time_seconds": round(elapsed, 1),
                "execution_mode": "polling",
            }
            return interaction.outputs[-1].text, metadata
            
        elif interaction.status == "failed":
            error_msg = getattr(interaction, 'error', 'Unknown error')
            print(f"\nâœ— ãƒªã‚µãƒ¼ãƒå¤±æ•—: {error_msg}")
            sys.exit(1)
            
        elif elapsed > max_seconds:
            print(f"\nâœ— ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {MAX_WAIT_MINUTES} åˆ†çµŒé")
            sys.exit(1)
        
        # é€²æ—è¡¨ç¤º
        status = getattr(interaction, 'status', 'in_progress')
        minutes = int(elapsed // 60)
        seconds = int(elapsed % 60)
        print(f"\r  [{minutes:02d}:{seconds:02d}] ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}", end="", flush=True)
        
        time.sleep(POLL_INTERVAL_SECONDS)


def run_research_streaming(client: genai.Client, prompt: str) -> tuple[str, dict]:
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ–¹å¼ã§ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    é€²æ—çŠ¶æ³ã¨æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã™ã‚‹ã€‚
    
    Returns:
        tuple: (çµæœãƒ†ã‚­ã‚¹ãƒˆ, ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸)
    """
    print(f"ãƒªã‚µãƒ¼ãƒé–‹å§‹ (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰)...")
    print(f"  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:100]}{'...' if len(prompt) > 100 else ''}")
    print(f"  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {AGENT_NAME}")
    print()
    print("=" * 60)
    
    start_time = time.time()
    
    stream = client.interactions.create(
        input=prompt,
        agent=AGENT_NAME,
        background=True,
        stream=True,
        agent_config={
            "type": "deep-research",
            "thinking_summaries": "auto"
        }
    )
    
    interaction_id = None
    last_event_id = None
    result_text = []
    
    try:
        for chunk in stream:
            if chunk.event_type == "interaction.start":
                interaction_id = chunk.interaction.id
                print(f"[é–‹å§‹] ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ ID: {interaction_id}\n")
            
            if hasattr(chunk, 'event_id') and chunk.event_id:
                last_event_id = chunk.event_id
            
            if chunk.event_type == "content.delta":
                if chunk.delta.type == "text":
                    text = chunk.delta.text
                    print(text, end="", flush=True)
                    result_text.append(text)
                elif chunk.delta.type == "thought_summary":
                    thought = chunk.delta.content.text
                    print(f"\nğŸ’­ æ€è€ƒ: {thought}\n", flush=True)
            
            elif chunk.event_type == "interaction.complete":
                print("\n" + "=" * 60)
                print("âœ“ ãƒªã‚µãƒ¼ãƒå®Œäº†")
                
    except Exception as e:
        print(f"\næ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸ: {e}")
        if interaction_id:
            print(f"å†æ¥ç¶šã‚’è©¦ã¿ã¾ã™...")
            # å†æ¥ç¶šãƒ­ã‚¸ãƒƒã‚¯
            result_text.append(_reconnect_and_resume(client, interaction_id, last_event_id))
    
    elapsed = time.time() - start_time
    metadata = {
        "interaction_id": interaction_id,
        "agent": AGENT_NAME,
        "status": "completed",
        "execution_time_seconds": round(elapsed, 1),
        "execution_mode": "streaming",
    }
    
    return "".join(result_text), metadata


def _reconnect_and_resume(client: genai.Client, interaction_id: str, last_event_id: str) -> str:
    """æ¥ç¶šãŒåˆ‡æ–­ã•ã‚ŒãŸå ´åˆã«å†æ¥ç¶šã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å†é–‹ã™ã‚‹ã€‚"""
    max_retries = 3
    result_text = []
    
    for attempt in range(max_retries):
        try:
            time.sleep(2)
            resume_stream = client.interactions.get(
                id=interaction_id,
                stream=True,
                last_event_id=last_event_id
            )
            
            for chunk in resume_stream:
                if hasattr(chunk, 'event_id') and chunk.event_id:
                    last_event_id = chunk.event_id
                
                if chunk.event_type == "content.delta":
                    if chunk.delta.type == "text":
                        text = chunk.delta.text
                        print(text, end="", flush=True)
                        result_text.append(text)
                
                elif chunk.event_type in ['interaction.complete', 'error']:
                    break
            
            return "".join(result_text)
            
        except Exception as e:
            print(f"å†æ¥ç¶šå¤±æ•— (è©¦è¡Œ {attempt + 1}/{max_retries}): {e}")
    
    print("å†æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    return "".join(result_text)


def build_prompt(query: str, format_instruction: str = None) -> str:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚"""
    prompt = query
    
    if format_instruction:
        prompt = f"{query}\n\nå‡ºåŠ›å½¢å¼:\n{format_instruction}"
    
    return prompt


def save_report(content: str, output_path: str, metadata: dict = None) -> None:
    """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãï¼‰ã€‚"""
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(content)
        
        if metadata:
            f.write("\n\n")
            f.write("---\n")
            f.write("<!-- Metadata -->\n")
            for key, value in metadata.items():
                if value is None:
                    f.write(f"{key}: null\n")
                elif isinstance(value, str):
                    # æ–‡å­—åˆ—ã«ç‰¹æ®Šæ–‡å­—ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã‚¯ã‚©ãƒ¼ãƒˆ
                    if any(c in value for c in [':', '#', '"', "'", '\n']):
                        f.write(f'{key}: "{value}"\n')
                    else:
                        f.write(f"{key}: {value}\n")
                else:
                    f.write(f"{key}: {value}\n")
            f.write("---\n")
    
    print(f"\nãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_path}")


def generate_output_filename(query: str) -> str:
    """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã€‚"""
    # ã‚¯ã‚¨ãƒªã®æœ€åˆã®30æ–‡å­—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨
    safe_query = "".join(c if c.isalnum() or c in "_ -" else "_" for c in query[:30])
    safe_query = safe_query.strip("_").replace(" ", "_")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"deep_research_{safe_query}_{timestamp}.md"


def main():
    parser = argparse.ArgumentParser(
        description="Gemini Deep Research ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œã™ã‚‹ã€‚",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python scripts/deep_research.py "EVãƒãƒƒãƒ†ãƒªãƒ¼ã®ç«¶äº‰ç’°å¢ƒã‚’èª¿æŸ»"
  python scripts/deep_research.py "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®æœ€æ–°å‹•å‘" --stream
  python scripts/deep_research.py "AIè¦åˆ¶ã®å›½éš›æ¯”è¼ƒ" --output reports/ai_regulation.md
        """
    )
    parser.add_argument(
        "query",
        help="ãƒªã‚µãƒ¼ãƒã®ã‚¯ã‚¨ãƒªï¼ˆè³ªå•ãƒ»æŒ‡ç¤ºï¼‰",
    )
    parser.add_argument(
        "--output", "-o",
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰",
    )
    parser.add_argument(
        "--output-dir",
        default=".",
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰",
    )
    parser.add_argument(
        "--stream", "-s",
        action="store_true",
        help="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆé€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºï¼‰",
    )
    parser.add_argument(
        "--format", "-f",
        dest="format_instruction",
        help="å‡ºåŠ›å½¢å¼ã®æŒ‡ç¤ºï¼ˆä¾‹: 'æŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã§'ï¼‰",
    )
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ãªã„ï¼ˆæ¨™æº–å‡ºåŠ›ã®ã¿ï¼‰",
    )
    
    args = parser.parse_args()
    
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
    client = create_client()
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    prompt = build_prompt(args.query, args.format_instruction)
    
    # ãƒªã‚µãƒ¼ãƒå®Ÿè¡Œ
    if args.stream:
        result, metadata = run_research_streaming(client, prompt)
    else:
        result, metadata = run_research_polling(client, prompt)
    
    # çµæœè¡¨ç¤ºãƒ»ä¿å­˜
    if not args.stream:
        print("\n" + "=" * 60)
        print("ãƒªã‚µãƒ¼ãƒçµæœ:")
        print("=" * 60)
        print(result)
    
    if not args.no_save:
        if args.output:
            output_path = args.output
        else:
            output_filename = generate_output_filename(args.query)
            output_path = os.path.join(args.output_dir, output_filename)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ æƒ…å ±ã‚’ä»˜ä¸
        metadata["query"] = args.query
        metadata["format_instruction"] = args.format_instruction
        metadata["generated_at"] = datetime.now().isoformat()
        metadata["output_file"] = output_path
        
        save_report(result, output_path, metadata)


if __name__ == "__main__":
    main()
